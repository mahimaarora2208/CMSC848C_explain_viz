2022-12-17 17:29:41,779.779 2838:inference.py:320   <module>(): param:
{'image_path': '../img30/img30_0.png',
 'model_name': 'GIT_BASE',
 'prefix': '',
 'type': 'test_git_inference_single_image'}
2022-12-17 17:30:33,753.753 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2022-12-17 17:30:33,756.756 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2022-12-17 17:30:33,756.756 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2022-12-17 17:30:33,757.757 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2022-12-17 17:30:33,757.757 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2022-12-17 17:30:33,757.757 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2022-12-17 17:30:33,757.757 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2022-12-17 17:30:33,757.757 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2022-12-17 17:30:33,757.757 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:30:33,757.757 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:30:33,757.757 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:30:33,758.758 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 17:30:33,759.759 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2022-12-17 17:30:33,760.760 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2022-12-17 17:30:33,761.761 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2022-12-17 17:30:33,762.762 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2022-12-17 17:30:33,763.763 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:30:33,764.764 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2022-12-17 17:30:33,764.764 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2022-12-17 17:30:33,764.764 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2022-12-17 17:30:33,764.764 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2022-12-17 17:30:33,764.764 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:30:33,764.764 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:30:33,764.764 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:30:33,765.765 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:30:33,765.765 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:30:33,765.765 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:30:33,765.765 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2022-12-17 17:30:33,765.765 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:30:33,765.765 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2022-12-17 17:30:33,765.765 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2022-12-17 17:30:33,765.765 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2022-12-17 17:30:33,766.766 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2022-12-17 17:30:33,766.766 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:30:33,766.766 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:30:33,766.766 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:30:33,766.766 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:30:33,766.766 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:30:33,766.766 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:30:33,766.766 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2022-12-17 17:30:33,767.767 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:30:33,767.767 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2022-12-17 17:30:33,767.767 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2022-12-17 17:30:33,767.767 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2022-12-17 17:30:33,767.767 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2022-12-17 17:30:33,767.767 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:30:33,767.767 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:30:33,767.767 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:30:33,767.767 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:30:33,768.768 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:30:33,768.768 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:30:33,768.768 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2022-12-17 17:30:33,768.768 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:30:33,768.768 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2022-12-17 17:30:33,768.768 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2022-12-17 17:30:33,768.768 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2022-12-17 17:30:33,769.769 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2022-12-17 17:30:33,769.769 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:30:33,769.769 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:30:33,769.769 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:30:33,769.769 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:30:33,769.769 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:30:33,769.769 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:30:33,769.769 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2022-12-17 17:30:33,770.770 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:30:33,770.770 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2022-12-17 17:30:33,770.770 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2022-12-17 17:30:33,770.770 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2022-12-17 17:30:33,770.770 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2022-12-17 17:30:33,770.770 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:30:33,770.770 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:30:33,770.770 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:30:33,770.770 2838:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:30:33,771.771 2838:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2022-12-17 17:30:33,771.771 2838:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2022-12-17 17:30:33,771.771 2838:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2022-12-17 17:30:33,771.771 2838:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2022-12-17 17:30:33,771.771 2838:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2022-12-17 17:30:33,771.771 2838:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2022-12-17 17:30:33,771.771 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:30:33,771.771 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:30:33,772.772 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2022-12-17 17:30:33,772.772 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:30:33,772.772 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2022-12-17 17:30:33,772.772 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:30:33,772.772 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2022-12-17 17:30:33,772.772 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:30:33,772.772 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2022-12-17 17:30:33,773.773 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:30:33,773.773 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:30:33,773.773 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:30:33,773.773 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:30:33,773.773 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:30:33,773.773 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2022-12-17 17:30:33,773.773 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2022-12-17 17:30:33,773.773 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:30:33,774.774 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:30:33,774.774 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2022-12-17 17:30:33,774.774 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:30:33,774.774 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2022-12-17 17:30:33,774.774 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:30:33,774.774 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2022-12-17 17:30:33,774.774 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:30:33,774.774 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2022-12-17 17:30:33,774.774 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:30:33,775.775 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:30:33,775.775 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:30:33,775.775 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:30:33,775.775 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:30:33,775.775 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2022-12-17 17:30:33,775.775 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2022-12-17 17:30:33,775.775 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:30:33,775.775 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:30:33,776.776 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:30:33,777.777 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2022-12-17 17:30:33,778.778 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:30:33,778.778 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:30:33,778.778 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:30:33,778.778 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:30:33,779.779 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:30:33,779.779 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2022-12-17 17:30:33,779.779 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2022-12-17 17:30:33,779.779 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:30:33,779.779 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:30:33,779.779 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2022-12-17 17:30:33,779.779 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:30:33,780.780 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2022-12-17 17:30:33,780.780 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:30:33,780.780 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2022-12-17 17:30:33,780.780 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:30:33,780.780 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2022-12-17 17:30:33,780.780 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:30:33,780.780 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:30:33,780.780 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:30:33,780.780 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:30:33,780.780 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:30:33,781.781 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2022-12-17 17:30:33,781.781 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2022-12-17 17:30:33,781.781 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:30:33,781.781 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:30:33,781.781 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2022-12-17 17:30:33,781.781 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:30:33,781.781 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2022-12-17 17:30:33,781.781 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:30:33,781.781 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2022-12-17 17:30:33,781.781 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:30:33,782.782 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2022-12-17 17:30:33,782.782 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:30:33,782.782 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:30:33,782.782 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:30:33,782.782 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:30:33,782.782 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:30:33,782.782 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2022-12-17 17:30:33,782.782 2838:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2022-12-17 17:30:33,782.782 2838:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2022-12-17 17:30:33,783.783 2838:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2022-12-17 17:30:33,783.783 2838:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2022-12-17 17:30:33,783.783 2838:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2022-12-17 17:30:33,783.783 2838:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2022-12-17 17:30:33,783.783 2838:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2022-12-17 17:30:33,785.785 2838:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2022-12-17 17:30:34,026.026 2838:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
2022-12-17 17:34:00,364.364 2838:inference.py:111 test_git_inference_single_image(): output: the sky is dark
2022-12-17 17:34:10,231.231 2861:inference.py:320   <module>(): param:
{'image_path': '../img30/img30_1.png',
 'model_name': 'GIT_BASE',
 'prefix': '',
 'type': 'test_git_inference_single_image'}
2022-12-17 17:34:32,077.077 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2022-12-17 17:34:32,081.081 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2022-12-17 17:34:32,081.081 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2022-12-17 17:34:32,081.081 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2022-12-17 17:34:32,081.081 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2022-12-17 17:34:32,081.081 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2022-12-17 17:34:32,082.082 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2022-12-17 17:34:32,082.082 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2022-12-17 17:34:32,082.082 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:34:32,082.082 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:34:32,082.082 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2022-12-17 17:34:32,083.083 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:34:32,083.083 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2022-12-17 17:34:32,083.083 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2022-12-17 17:34:32,083.083 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2022-12-17 17:34:32,083.083 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2022-12-17 17:34:32,083.083 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:34:32,083.083 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:34:32,084.084 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:34:32,084.084 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:34:32,084.084 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:34:32,084.084 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:34:32,084.084 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2022-12-17 17:34:32,085.085 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:34:32,085.085 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2022-12-17 17:34:32,085.085 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2022-12-17 17:34:32,085.085 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2022-12-17 17:34:32,085.085 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2022-12-17 17:34:32,085.085 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:34:32,086.086 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:34:32,086.086 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:34:32,086.086 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:34:32,087.087 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2022-12-17 17:34:32,087.087 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 17:34:32,087.087 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2022-12-17 17:34:32,088.088 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2022-12-17 17:34:32,088.088 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2022-12-17 17:34:32,088.088 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2022-12-17 17:34:32,089.089 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2022-12-17 17:34:32,089.089 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2022-12-17 17:34:32,089.089 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 17:34:32,090.090 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 17:34:32,090.090 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2022-12-17 17:34:32,090.090 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 17:34:32,090.090 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2022-12-17 17:34:32,090.090 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 17:34:32,091.091 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2022-12-17 17:34:32,091.091 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2022-12-17 17:34:32,091.091 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2022-12-17 17:34:32,091.091 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2022-12-17 17:34:32,091.091 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2022-12-17 17:34:32,092.092 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2022-12-17 17:34:32,092.092 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 17:34:32,092.092 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 17:34:32,092.092 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2022-12-17 17:34:32,092.092 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 17:34:32,093.093 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:34:32,093.093 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:34:32,093.093 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2022-12-17 17:34:32,093.093 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:34:32,093.093 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2022-12-17 17:34:32,093.093 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2022-12-17 17:34:32,094.094 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2022-12-17 17:34:32,094.094 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2022-12-17 17:34:32,094.094 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:34:32,094.094 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:34:32,094.094 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:34:32,094.094 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:34:32,095.095 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:34:32,095.095 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:34:32,095.095 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2022-12-17 17:34:32,095.095 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:34:32,095.095 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2022-12-17 17:34:32,095.095 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2022-12-17 17:34:32,095.095 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2022-12-17 17:34:32,095.095 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2022-12-17 17:34:32,096.096 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:34:32,096.096 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:34:32,096.096 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:34:32,096.096 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:34:32,096.096 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:34:32,096.096 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:34:32,096.096 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2022-12-17 17:34:32,097.097 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:34:32,097.097 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2022-12-17 17:34:32,097.097 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2022-12-17 17:34:32,097.097 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2022-12-17 17:34:32,097.097 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2022-12-17 17:34:32,097.097 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:34:32,097.097 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:34:32,098.098 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:34:32,098.098 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:34:32,098.098 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:34:32,098.098 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:34:32,098.098 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2022-12-17 17:34:32,098.098 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:34:32,098.098 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2022-12-17 17:34:32,098.098 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2022-12-17 17:34:32,098.098 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2022-12-17 17:34:32,099.099 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2022-12-17 17:34:32,099.099 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:34:32,099.099 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:34:32,099.099 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:34:32,099.099 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:34:32,099.099 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:34:32,099.099 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:34:32,100.100 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2022-12-17 17:34:32,100.100 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:34:32,100.100 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2022-12-17 17:34:32,100.100 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2022-12-17 17:34:32,100.100 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2022-12-17 17:34:32,100.100 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2022-12-17 17:34:32,100.100 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:34:32,101.101 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:34:32,101.101 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:34:32,101.101 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:34:32,101.101 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:34:32,101.101 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:34:32,101.101 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2022-12-17 17:34:32,101.101 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:34:32,101.101 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2022-12-17 17:34:32,102.102 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2022-12-17 17:34:32,102.102 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2022-12-17 17:34:32,102.102 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2022-12-17 17:34:32,102.102 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:34:32,102.102 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:34:32,103.103 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:34:32,103.103 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:34:32,103.103 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:34:32,103.103 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:34:32,104.104 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2022-12-17 17:34:32,104.104 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:34:32,104.104 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2022-12-17 17:34:32,104.104 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2022-12-17 17:34:32,104.104 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2022-12-17 17:34:32,104.104 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2022-12-17 17:34:32,105.105 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:34:32,105.105 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:34:32,105.105 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:34:32,106.106 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:34:32,106.106 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:34:32,106.106 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:34:32,106.106 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2022-12-17 17:34:32,106.106 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:34:32,107.107 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2022-12-17 17:34:32,107.107 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2022-12-17 17:34:32,107.107 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2022-12-17 17:34:32,107.107 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2022-12-17 17:34:32,107.107 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:34:32,108.108 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:34:32,108.108 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:34:32,110.110 2861:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:34:32,110.110 2861:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2022-12-17 17:34:32,111.111 2861:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2022-12-17 17:34:32,111.111 2861:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2022-12-17 17:34:32,111.111 2861:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2022-12-17 17:34:32,111.111 2861:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2022-12-17 17:34:32,111.111 2861:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2022-12-17 17:34:32,112.112 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:34:32,112.112 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:34:32,112.112 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2022-12-17 17:34:32,112.112 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:34:32,112.112 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2022-12-17 17:34:32,113.113 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:34:32,113.113 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2022-12-17 17:34:32,113.113 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:34:32,113.113 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2022-12-17 17:34:32,113.113 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:34:32,113.113 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:34:32,114.114 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:34:32,114.114 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:34:32,114.114 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:34:32,114.114 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2022-12-17 17:34:32,114.114 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2022-12-17 17:34:32,114.114 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:34:32,115.115 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:34:32,115.115 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2022-12-17 17:34:32,115.115 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:34:32,115.115 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2022-12-17 17:34:32,115.115 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:34:32,115.115 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2022-12-17 17:34:32,115.115 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:34:32,116.116 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2022-12-17 17:34:32,116.116 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:34:32,116.116 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:34:32,116.116 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:34:32,116.116 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:34:32,116.116 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:34:32,116.116 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2022-12-17 17:34:32,116.116 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2022-12-17 17:34:32,117.117 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:34:32,117.117 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:34:32,117.117 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2022-12-17 17:34:32,117.117 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:34:32,117.117 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2022-12-17 17:34:32,117.117 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:34:32,118.118 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2022-12-17 17:34:32,118.118 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:34:32,118.118 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2022-12-17 17:34:32,118.118 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:34:32,118.118 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:34:32,119.119 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:34:32,119.119 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:34:32,119.119 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:34:32,119.119 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2022-12-17 17:34:32,120.120 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2022-12-17 17:34:32,120.120 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:34:32,120.120 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:34:32,120.120 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2022-12-17 17:34:32,120.120 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:34:32,120.120 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2022-12-17 17:34:32,121.121 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:34:32,121.121 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2022-12-17 17:34:32,121.121 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:34:32,121.121 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2022-12-17 17:34:32,121.121 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:34:32,124.124 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:34:32,124.124 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:34:32,125.125 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:34:32,125.125 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:34:32,125.125 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2022-12-17 17:34:32,125.125 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2022-12-17 17:34:32,125.125 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:34:32,126.126 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:34:32,126.126 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2022-12-17 17:34:32,126.126 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:34:32,126.126 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2022-12-17 17:34:32,126.126 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:34:32,126.126 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2022-12-17 17:34:32,127.127 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:34:32,127.127 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2022-12-17 17:34:32,127.127 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:34:32,127.127 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:34:32,127.127 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:34:32,127.127 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:34:32,128.128 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:34:32,128.128 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2022-12-17 17:34:32,128.128 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2022-12-17 17:34:32,128.128 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:34:32,128.128 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:34:32,128.128 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2022-12-17 17:34:32,129.129 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:34:32,129.129 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2022-12-17 17:34:32,129.129 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:34:32,129.129 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2022-12-17 17:34:32,129.129 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:34:32,129.129 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2022-12-17 17:34:32,130.130 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:34:32,130.130 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:34:32,130.130 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:34:32,130.130 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:34:32,130.130 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:34:32,131.131 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2022-12-17 17:34:32,131.131 2861:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2022-12-17 17:34:32,131.131 2861:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2022-12-17 17:34:32,131.131 2861:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2022-12-17 17:34:32,131.131 2861:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2022-12-17 17:34:32,131.131 2861:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2022-12-17 17:34:32,131.131 2861:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2022-12-17 17:34:32,132.132 2861:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2022-12-17 17:34:32,135.135 2861:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2022-12-17 17:34:32,444.444 2861:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
2022-12-17 17:35:50,611.611 2861:inference.py:111 test_git_inference_single_image(): output: a wall on the side of a building
2022-12-17 17:35:56,590.590 2872:inference.py:320   <module>(): param:
{'image_path': '../img30/img30_2.png',
 'model_name': 'GIT_BASE',
 'prefix': '',
 'type': 'test_git_inference_single_image'}
2022-12-17 17:36:36,641.641 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2022-12-17 17:36:36,647.647 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2022-12-17 17:36:36,647.647 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2022-12-17 17:36:36,648.648 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2022-12-17 17:36:36,648.648 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2022-12-17 17:36:36,648.648 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2022-12-17 17:36:36,648.648 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2022-12-17 17:36:36,650.650 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2022-12-17 17:36:36,650.650 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:36:36,650.650 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:36:36,650.650 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2022-12-17 17:36:36,650.650 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:36:36,650.650 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2022-12-17 17:36:36,650.650 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2022-12-17 17:36:36,650.650 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2022-12-17 17:36:36,650.650 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2022-12-17 17:36:36,651.651 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2022-12-17 17:36:36,652.652 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:36:36,652.652 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:36:36,652.652 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:36:36,652.652 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:36:36,652.652 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2022-12-17 17:36:36,652.652 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 17:36:36,652.652 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2022-12-17 17:36:36,652.652 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2022-12-17 17:36:36,653.653 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2022-12-17 17:36:36,653.653 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2022-12-17 17:36:36,653.653 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2022-12-17 17:36:36,653.653 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2022-12-17 17:36:36,653.653 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 17:36:36,653.653 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 17:36:36,654.654 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2022-12-17 17:36:36,654.654 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 17:36:36,654.654 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2022-12-17 17:36:36,654.654 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 17:36:36,654.654 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2022-12-17 17:36:36,654.654 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2022-12-17 17:36:36,655.655 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2022-12-17 17:36:36,655.655 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2022-12-17 17:36:36,655.655 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2022-12-17 17:36:36,655.655 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2022-12-17 17:36:36,655.655 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 17:36:36,656.656 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 17:36:36,656.656 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2022-12-17 17:36:36,656.656 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 17:36:36,656.656 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:36:36,656.656 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:36:36,656.656 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2022-12-17 17:36:36,657.657 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:36:36,657.657 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2022-12-17 17:36:36,669.669 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2022-12-17 17:36:36,669.669 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2022-12-17 17:36:36,669.669 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2022-12-17 17:36:36,669.669 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:36:36,669.669 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:36:36,669.669 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:36:36,669.669 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:36:36,670.670 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:36:36,670.670 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:36:36,670.670 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2022-12-17 17:36:36,670.670 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:36:36,670.670 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2022-12-17 17:36:36,670.670 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2022-12-17 17:36:36,670.670 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2022-12-17 17:36:36,671.671 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2022-12-17 17:36:36,671.671 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:36:36,671.671 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:36:36,671.671 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:36:36,671.671 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:36:36,672.672 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:36:36,672.672 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:36:36,672.672 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2022-12-17 17:36:36,672.672 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:36:36,672.672 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2022-12-17 17:36:36,673.673 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2022-12-17 17:36:36,673.673 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2022-12-17 17:36:36,673.673 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2022-12-17 17:36:36,673.673 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:36:36,673.673 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:36:36,673.673 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:36:36,674.674 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:36:36,674.674 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:36:36,674.674 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:36:36,674.674 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2022-12-17 17:36:36,674.674 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:36:36,674.674 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2022-12-17 17:36:36,675.675 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2022-12-17 17:36:36,675.675 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2022-12-17 17:36:36,675.675 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2022-12-17 17:36:36,675.675 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:36:36,675.675 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:36:36,676.676 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:36:36,676.676 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:36:36,676.676 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:36:36,679.679 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:36:36,680.680 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2022-12-17 17:36:36,680.680 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:36:36,680.680 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2022-12-17 17:36:36,680.680 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2022-12-17 17:36:36,680.680 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2022-12-17 17:36:36,681.681 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2022-12-17 17:36:36,681.681 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:36:36,682.682 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:36:36,682.682 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:36:36,684.684 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:36:36,685.685 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:36:36,685.685 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:36:36,685.685 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2022-12-17 17:36:36,685.685 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:36:36,685.685 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2022-12-17 17:36:36,685.685 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2022-12-17 17:36:36,685.685 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2022-12-17 17:36:36,686.686 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2022-12-17 17:36:36,686.686 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:36:36,686.686 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:36:36,686.686 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:36:36,686.686 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:36:36,686.686 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:36:36,687.687 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:36:36,687.687 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2022-12-17 17:36:36,687.687 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:36:36,687.687 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2022-12-17 17:36:36,687.687 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2022-12-17 17:36:36,687.687 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2022-12-17 17:36:36,687.687 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2022-12-17 17:36:36,688.688 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:36:36,688.688 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:36:36,688.688 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:36:36,688.688 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:36:36,688.688 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:36:36,688.688 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:36:36,688.688 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2022-12-17 17:36:36,689.689 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:36:36,689.689 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2022-12-17 17:36:36,689.689 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2022-12-17 17:36:36,689.689 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2022-12-17 17:36:36,689.689 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2022-12-17 17:36:36,689.689 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:36:36,689.689 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:36:36,689.689 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:36:36,690.690 2872:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:36:36,690.690 2872:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2022-12-17 17:36:36,690.690 2872:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2022-12-17 17:36:36,690.690 2872:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2022-12-17 17:36:36,690.690 2872:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2022-12-17 17:36:36,690.690 2872:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2022-12-17 17:36:36,691.691 2872:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2022-12-17 17:36:36,691.691 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:36:36,691.691 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:36:36,691.691 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2022-12-17 17:36:36,691.691 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:36:36,691.691 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2022-12-17 17:36:36,692.692 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:36:36,692.692 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2022-12-17 17:36:36,692.692 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:36:36,692.692 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2022-12-17 17:36:36,692.692 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:36:36,693.693 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:36:36,693.693 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:36:36,693.693 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:36:36,693.693 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:36:36,693.693 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2022-12-17 17:36:36,694.694 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2022-12-17 17:36:36,694.694 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:36:36,694.694 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:36:36,694.694 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2022-12-17 17:36:36,694.694 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:36:36,695.695 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2022-12-17 17:36:36,695.695 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:36:36,695.695 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2022-12-17 17:36:36,696.696 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:36:36,696.696 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2022-12-17 17:36:36,697.697 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:36:36,697.697 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:36:36,704.704 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:36:36,705.705 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:36:36,705.705 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:36:36,705.705 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2022-12-17 17:36:36,705.705 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2022-12-17 17:36:36,705.705 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:36:36,706.706 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:36:36,706.706 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2022-12-17 17:36:36,706.706 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:36:36,706.706 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2022-12-17 17:36:36,706.706 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:36:36,706.706 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2022-12-17 17:36:36,707.707 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:36:36,707.707 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2022-12-17 17:36:36,707.707 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:36:36,707.707 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:36:36,707.707 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:36:36,707.707 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:36:36,708.708 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:36:36,708.708 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2022-12-17 17:36:36,708.708 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2022-12-17 17:36:36,708.708 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:36:36,708.708 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:36:36,709.709 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2022-12-17 17:36:36,709.709 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:36:36,709.709 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2022-12-17 17:36:36,709.709 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:36:36,709.709 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2022-12-17 17:36:36,709.709 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:36:36,710.710 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2022-12-17 17:36:36,710.710 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:36:36,710.710 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:36:36,710.710 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:36:36,710.710 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:36:36,710.710 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:36:36,711.711 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2022-12-17 17:36:36,711.711 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2022-12-17 17:36:36,711.711 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:36:36,711.711 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:36:36,711.711 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2022-12-17 17:36:36,712.712 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:36:36,712.712 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2022-12-17 17:36:36,712.712 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:36:36,712.712 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2022-12-17 17:36:36,712.712 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:36:36,712.712 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2022-12-17 17:36:36,713.713 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:36:36,713.713 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:36:36,713.713 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:36:36,713.713 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:36:36,714.714 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:36:36,714.714 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2022-12-17 17:36:36,715.715 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2022-12-17 17:36:36,715.715 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:36:36,716.716 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:36:36,716.716 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2022-12-17 17:36:36,716.716 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:36:36,716.716 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2022-12-17 17:36:36,717.717 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:36:36,717.717 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2022-12-17 17:36:36,717.717 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:36:36,717.717 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2022-12-17 17:36:36,717.717 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:36:36,718.718 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:36:36,718.718 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:36:36,718.718 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:36:36,719.719 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:36:36,719.719 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2022-12-17 17:36:36,719.719 2872:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2022-12-17 17:36:36,719.719 2872:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2022-12-17 17:36:36,719.719 2872:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2022-12-17 17:36:36,720.720 2872:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2022-12-17 17:36:36,720.720 2872:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2022-12-17 17:36:36,720.720 2872:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2022-12-17 17:36:36,721.721 2872:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2022-12-17 17:36:36,738.738 2872:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2022-12-17 17:36:37,636.636 2872:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
2022-12-17 17:37:32,661.661 2872:inference.py:111 test_git_inference_single_image(): output: the road is tarmacked
2022-12-17 17:37:38,349.349 2883:inference.py:320   <module>(): param:
{'image_path': '../img30/img30_3.png',
 'model_name': 'GIT_BASE',
 'prefix': '',
 'type': 'test_git_inference_single_image'}
2022-12-17 17:37:52,271.271 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2022-12-17 17:37:52,272.272 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2022-12-17 17:37:52,272.272 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2022-12-17 17:37:52,272.272 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2022-12-17 17:37:52,272.272 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2022-12-17 17:37:52,272.272 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2022-12-17 17:37:52,272.272 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2022-12-17 17:37:52,272.272 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2022-12-17 17:37:52,272.272 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:37:52,272.272 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:37:52,272.272 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2022-12-17 17:37:52,273.273 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:37:52,273.273 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2022-12-17 17:37:52,273.273 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2022-12-17 17:37:52,273.273 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2022-12-17 17:37:52,273.273 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2022-12-17 17:37:52,273.273 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:37:52,273.273 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:37:52,274.274 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:37:52,274.274 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:37:52,274.274 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:37:52,274.274 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:37:52,274.274 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2022-12-17 17:37:52,274.274 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:37:52,274.274 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2022-12-17 17:37:52,275.275 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2022-12-17 17:37:52,275.275 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2022-12-17 17:37:52,275.275 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2022-12-17 17:37:52,275.275 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:37:52,275.275 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:37:52,275.275 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:37:52,275.275 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:37:52,275.275 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2022-12-17 17:37:52,276.276 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 17:37:52,276.276 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2022-12-17 17:37:52,276.276 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2022-12-17 17:37:52,276.276 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2022-12-17 17:37:52,276.276 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2022-12-17 17:37:52,276.276 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2022-12-17 17:37:52,276.276 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2022-12-17 17:37:52,276.276 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 17:37:52,277.277 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 17:37:52,277.277 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2022-12-17 17:37:52,277.277 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 17:37:52,277.277 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2022-12-17 17:37:52,277.277 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 17:37:52,277.277 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2022-12-17 17:37:52,277.277 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2022-12-17 17:37:52,278.278 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2022-12-17 17:37:52,278.278 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2022-12-17 17:37:52,278.278 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2022-12-17 17:37:52,278.278 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2022-12-17 17:37:52,278.278 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 17:37:52,278.278 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 17:37:52,278.278 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2022-12-17 17:37:52,278.278 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 17:37:52,279.279 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:37:52,279.279 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:37:52,279.279 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2022-12-17 17:37:52,279.279 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:37:52,279.279 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2022-12-17 17:37:52,279.279 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2022-12-17 17:37:52,279.279 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2022-12-17 17:37:52,279.279 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2022-12-17 17:37:52,279.279 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2022-12-17 17:37:52,280.280 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:37:52,281.281 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:37:52,281.281 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:37:52,281.281 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:37:52,281.281 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:37:52,281.281 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:37:52,281.281 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2022-12-17 17:37:52,281.281 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:37:52,281.281 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2022-12-17 17:37:52,282.282 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2022-12-17 17:37:52,282.282 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2022-12-17 17:37:52,282.282 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2022-12-17 17:37:52,282.282 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:37:52,282.282 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:37:52,282.282 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:37:52,283.283 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:37:52,283.283 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:37:52,283.283 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:37:52,283.283 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2022-12-17 17:37:52,283.283 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:37:52,283.283 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2022-12-17 17:37:52,283.283 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2022-12-17 17:37:52,284.284 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2022-12-17 17:37:52,284.284 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2022-12-17 17:37:52,284.284 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:37:52,284.284 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:37:52,284.284 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:37:52,284.284 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:37:52,284.284 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:37:52,285.285 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:37:52,285.285 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2022-12-17 17:37:52,285.285 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:37:52,285.285 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2022-12-17 17:37:52,285.285 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2022-12-17 17:37:52,285.285 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2022-12-17 17:37:52,286.286 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2022-12-17 17:37:52,286.286 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:37:52,286.286 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:37:52,286.286 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:37:52,286.286 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:37:52,286.286 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:37:52,286.286 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:37:52,287.287 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2022-12-17 17:37:52,287.287 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:37:52,287.287 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2022-12-17 17:37:52,287.287 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2022-12-17 17:37:52,287.287 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2022-12-17 17:37:52,287.287 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2022-12-17 17:37:52,287.287 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:37:52,288.288 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:37:52,288.288 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:37:52,288.288 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:37:52,288.288 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:37:52,288.288 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:37:52,288.288 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2022-12-17 17:37:52,289.289 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:37:52,289.289 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2022-12-17 17:37:52,289.289 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2022-12-17 17:37:52,289.289 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2022-12-17 17:37:52,289.289 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2022-12-17 17:37:52,289.289 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:37:52,289.289 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:37:52,290.290 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:37:52,290.290 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:37:52,290.290 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:37:52,290.290 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:37:52,290.290 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2022-12-17 17:37:52,290.290 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:37:52,290.290 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2022-12-17 17:37:52,291.291 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2022-12-17 17:37:52,291.291 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2022-12-17 17:37:52,291.291 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2022-12-17 17:37:52,291.291 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:37:52,291.291 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:37:52,291.291 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:37:52,291.291 2883:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:37:52,292.292 2883:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2022-12-17 17:37:52,292.292 2883:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2022-12-17 17:37:52,292.292 2883:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2022-12-17 17:37:52,292.292 2883:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2022-12-17 17:37:52,292.292 2883:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2022-12-17 17:37:52,292.292 2883:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2022-12-17 17:37:52,292.292 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:37:52,292.292 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:37:52,293.293 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2022-12-17 17:37:52,293.293 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:37:52,293.293 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2022-12-17 17:37:52,293.293 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:37:52,293.293 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2022-12-17 17:37:52,293.293 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:37:52,293.293 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2022-12-17 17:37:52,294.294 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:37:52,294.294 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:37:52,294.294 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:37:52,294.294 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:37:52,294.294 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:37:52,294.294 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2022-12-17 17:37:52,294.294 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2022-12-17 17:37:52,294.294 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:37:52,294.294 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:37:52,295.295 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2022-12-17 17:37:52,295.295 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:37:52,295.295 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2022-12-17 17:37:52,295.295 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:37:52,295.295 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2022-12-17 17:37:52,295.295 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:37:52,295.295 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2022-12-17 17:37:52,295.295 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:37:52,295.295 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:37:52,296.296 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:37:52,296.296 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:37:52,296.296 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:37:52,296.296 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2022-12-17 17:37:52,296.296 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2022-12-17 17:37:52,296.296 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:37:52,296.296 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:37:52,296.296 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2022-12-17 17:37:52,296.296 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:37:52,297.297 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2022-12-17 17:37:52,297.297 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:37:52,297.297 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2022-12-17 17:37:52,297.297 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:37:52,297.297 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2022-12-17 17:37:52,297.297 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:37:52,297.297 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:37:52,298.298 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:37:52,298.298 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:37:52,298.298 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:37:52,298.298 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2022-12-17 17:37:52,298.298 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2022-12-17 17:37:52,298.298 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:37:52,298.298 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:37:52,298.298 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2022-12-17 17:37:52,299.299 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:37:52,299.299 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2022-12-17 17:37:52,299.299 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:37:52,299.299 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2022-12-17 17:37:52,299.299 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:37:52,299.299 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2022-12-17 17:37:52,299.299 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:37:52,300.300 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:37:52,300.300 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:37:52,300.300 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:37:52,300.300 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:37:52,300.300 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2022-12-17 17:37:52,300.300 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2022-12-17 17:37:52,300.300 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:37:52,300.300 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:37:52,301.301 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2022-12-17 17:37:52,301.301 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:37:52,301.301 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2022-12-17 17:37:52,301.301 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:37:52,301.301 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2022-12-17 17:37:52,301.301 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:37:52,301.301 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2022-12-17 17:37:52,302.302 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:37:52,302.302 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:37:52,302.302 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:37:52,302.302 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:37:52,302.302 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:37:52,302.302 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2022-12-17 17:37:52,302.302 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2022-12-17 17:37:52,303.303 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:37:52,303.303 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:37:52,303.303 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2022-12-17 17:37:52,303.303 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:37:52,303.303 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2022-12-17 17:37:52,303.303 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:37:52,303.303 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2022-12-17 17:37:52,304.304 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:37:52,304.304 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2022-12-17 17:37:52,304.304 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:37:52,304.304 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:37:52,304.304 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:37:52,304.304 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:37:52,304.304 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:37:52,304.304 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2022-12-17 17:37:52,305.305 2883:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2022-12-17 17:37:52,305.305 2883:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2022-12-17 17:37:52,305.305 2883:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2022-12-17 17:37:52,305.305 2883:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2022-12-17 17:37:52,305.305 2883:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2022-12-17 17:37:52,305.305 2883:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2022-12-17 17:37:52,306.306 2883:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2022-12-17 17:37:52,308.308 2883:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2022-12-17 17:37:52,599.599 2883:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
2022-12-17 17:38:24,829.829 2883:inference.py:111 test_git_inference_single_image(): output: the road is tarmacked
2022-12-17 17:38:37,764.764 2905:inference.py:320   <module>(): param:
{'image_path': '../img30/img30_4.png',
 'model_name': 'GIT_BASE',
 'prefix': '',
 'type': 'test_git_inference_single_image'}
2022-12-17 17:39:05,096.096 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2022-12-17 17:39:05,096.096 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2022-12-17 17:39:05,096.096 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2022-12-17 17:39:05,096.096 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2022-12-17 17:39:05,096.096 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2022-12-17 17:39:05,096.096 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2022-12-17 17:39:05,097.097 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2022-12-17 17:39:05,097.097 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2022-12-17 17:39:05,097.097 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:39:05,097.097 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:39:05,097.097 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2022-12-17 17:39:05,097.097 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:39:05,097.097 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2022-12-17 17:39:05,097.097 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2022-12-17 17:39:05,097.097 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2022-12-17 17:39:05,098.098 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2022-12-17 17:39:05,099.099 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2022-12-17 17:39:05,099.099 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2022-12-17 17:39:05,099.099 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:39:05,099.099 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:39:05,099.099 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:39:05,099.099 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:39:05,099.099 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2022-12-17 17:39:05,099.099 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 17:39:05,099.099 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 17:39:05,100.100 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2022-12-17 17:39:05,101.101 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:39:05,102.102 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2022-12-17 17:39:05,102.102 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2022-12-17 17:39:05,102.102 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2022-12-17 17:39:05,102.102 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2022-12-17 17:39:05,102.102 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:39:05,102.102 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:39:05,102.102 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:39:05,102.102 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:39:05,103.103 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:39:05,103.103 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:39:05,103.103 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2022-12-17 17:39:05,103.103 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:39:05,103.103 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2022-12-17 17:39:05,103.103 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2022-12-17 17:39:05,103.103 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2022-12-17 17:39:05,103.103 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2022-12-17 17:39:05,103.103 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:39:05,104.104 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:39:05,104.104 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:39:05,104.104 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:39:05,104.104 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:39:05,104.104 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:39:05,104.104 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2022-12-17 17:39:05,104.104 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:39:05,104.104 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2022-12-17 17:39:05,104.104 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2022-12-17 17:39:05,105.105 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2022-12-17 17:39:05,105.105 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2022-12-17 17:39:05,105.105 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:39:05,105.105 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:39:05,105.105 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:39:05,105.105 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:39:05,105.105 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:39:05,105.105 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:39:05,105.105 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2022-12-17 17:39:05,105.105 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:39:05,106.106 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2022-12-17 17:39:05,106.106 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2022-12-17 17:39:05,106.106 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2022-12-17 17:39:05,106.106 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2022-12-17 17:39:05,106.106 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:39:05,106.106 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:39:05,106.106 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:39:05,106.106 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:39:05,106.106 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:39:05,107.107 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:39:05,107.107 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2022-12-17 17:39:05,107.107 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:39:05,107.107 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2022-12-17 17:39:05,107.107 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2022-12-17 17:39:05,107.107 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2022-12-17 17:39:05,107.107 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2022-12-17 17:39:05,107.107 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:39:05,108.108 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:39:05,108.108 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:39:05,108.108 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:39:05,108.108 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:39:05,108.108 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:39:05,108.108 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2022-12-17 17:39:05,108.108 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:39:05,108.108 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2022-12-17 17:39:05,108.108 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2022-12-17 17:39:05,109.109 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2022-12-17 17:39:05,109.109 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2022-12-17 17:39:05,109.109 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:39:05,109.109 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:39:05,109.109 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:39:05,109.109 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:39:05,109.109 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:39:05,109.109 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:39:05,109.109 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2022-12-17 17:39:05,109.109 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:39:05,110.110 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2022-12-17 17:39:05,110.110 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2022-12-17 17:39:05,110.110 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2022-12-17 17:39:05,110.110 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2022-12-17 17:39:05,110.110 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:39:05,110.110 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:39:05,110.110 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:39:05,110.110 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:39:05,110.110 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2022-12-17 17:39:05,110.110 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 17:39:05,111.111 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2022-12-17 17:39:05,111.111 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2022-12-17 17:39:05,111.111 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2022-12-17 17:39:05,111.111 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2022-12-17 17:39:05,111.111 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2022-12-17 17:39:05,111.111 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2022-12-17 17:39:05,111.111 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 17:39:05,111.111 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 17:39:05,111.111 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2022-12-17 17:39:05,112.112 2905:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 17:39:05,112.112 2905:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2022-12-17 17:39:05,112.112 2905:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2022-12-17 17:39:05,112.112 2905:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2022-12-17 17:39:05,112.112 2905:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2022-12-17 17:39:05,112.112 2905:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2022-12-17 17:39:05,112.112 2905:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2022-12-17 17:39:05,112.112 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:39:05,112.112 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:39:05,113.113 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2022-12-17 17:39:05,113.113 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:39:05,113.113 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2022-12-17 17:39:05,113.113 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:39:05,113.113 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2022-12-17 17:39:05,113.113 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:39:05,113.113 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2022-12-17 17:39:05,113.113 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:39:05,113.113 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:39:05,113.113 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:39:05,114.114 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:39:05,114.114 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:39:05,114.114 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2022-12-17 17:39:05,114.114 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2022-12-17 17:39:05,114.114 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:39:05,114.114 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:39:05,114.114 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2022-12-17 17:39:05,114.114 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:39:05,114.114 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2022-12-17 17:39:05,115.115 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2022-12-17 17:39:05,116.116 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:39:05,116.116 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:39:05,116.116 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2022-12-17 17:39:05,116.116 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:39:05,116.116 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2022-12-17 17:39:05,116.116 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:39:05,116.116 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2022-12-17 17:39:05,116.116 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:39:05,116.116 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2022-12-17 17:39:05,116.116 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:39:05,117.117 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2022-12-17 17:39:05,118.118 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:39:05,118.118 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2022-12-17 17:39:05,118.118 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:39:05,118.118 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2022-12-17 17:39:05,118.118 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:39:05,118.118 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:39:05,118.118 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:39:05,118.118 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:39:05,118.118 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:39:05,119.119 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2022-12-17 17:39:05,119.119 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2022-12-17 17:39:05,119.119 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:39:05,119.119 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:39:05,119.119 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2022-12-17 17:39:05,119.119 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:39:05,119.119 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2022-12-17 17:39:05,119.119 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:39:05,119.119 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2022-12-17 17:39:05,120.120 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:39:05,120.120 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2022-12-17 17:39:05,120.120 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:39:05,120.120 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:39:05,120.120 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:39:05,120.120 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:39:05,120.120 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:39:05,120.120 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2022-12-17 17:39:05,120.120 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2022-12-17 17:39:05,120.120 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 17:39:05,121.121 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 17:39:05,121.121 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2022-12-17 17:39:05,121.121 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2022-12-17 17:39:05,121.121 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2022-12-17 17:39:05,121.121 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2022-12-17 17:39:05,121.121 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2022-12-17 17:39:05,121.121 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2022-12-17 17:39:05,121.121 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2022-12-17 17:39:05,122.122 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2022-12-17 17:39:05,122.122 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2022-12-17 17:39:05,122.122 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 17:39:05,122.122 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2022-12-17 17:39:05,122.122 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2022-12-17 17:39:05,122.122 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2022-12-17 17:39:05,122.122 2905:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2022-12-17 17:39:05,122.122 2905:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2022-12-17 17:39:05,122.122 2905:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2022-12-17 17:39:05,122.122 2905:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2022-12-17 17:39:05,123.123 2905:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2022-12-17 17:39:05,123.123 2905:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2022-12-17 17:39:05,123.123 2905:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2022-12-17 17:39:05,125.125 2905:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2022-12-17 17:39:05,224.224 2905:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
2022-12-17 17:39:43,968.968 2905:inference.py:111 test_git_inference_single_image(): output: a wall on the side of a building
