2022-12-17 16:55:21,023.023 2516:inference.py:320   <module>(): param:
{'image_path': '../img8/img8_0.png',
 'model_name': 'GIT_BASE',
 'prefix': '',
 'type': 'test_git_inference_single_image'}
2022-12-17 16:55:26,638.638 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2022-12-17 16:55:26,638.638 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2022-12-17 16:55:26,638.638 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2022-12-17 16:55:26,638.638 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:55:26,639.639 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2022-12-17 16:55:26,640.640 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2022-12-17 16:55:26,641.641 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:55:26,642.642 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2022-12-17 16:55:26,643.643 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2022-12-17 16:55:26,644.644 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:55:26,645.645 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:55:26,646.646 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2022-12-17 16:55:26,647.647 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2022-12-17 16:55:26,648.648 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2022-12-17 16:55:26,649.649 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:55:26,650.650 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:55:26,651.651 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:55:26,652.652 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:55:26,653.653 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:55:26,654.654 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:55:26,655.655 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:55:26,655.655 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:55:26,655.655 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2022-12-17 16:55:26,655.655 2516:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2022-12-17 16:55:26,655.655 2516:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2022-12-17 16:55:26,655.655 2516:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2022-12-17 16:55:26,655.655 2516:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2022-12-17 16:55:26,655.655 2516:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2022-12-17 16:55:26,655.655 2516:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2022-12-17 16:55:26,655.655 2516:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2022-12-17 16:55:26,657.657 2516:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2022-12-17 16:55:26,745.745 2516:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
2022-12-17 16:56:00,613.613 2516:inference.py:111 test_git_inference_single_image(): output: a tree in a city
2022-12-17 16:56:02,473.473 2527:inference.py:320   <module>(): param:
{'image_path': '../img8/img8_1.png',
 'model_name': 'GIT_BASE',
 'prefix': '',
 'type': 'test_git_inference_single_image'}
2022-12-17 16:56:27,737.737 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2022-12-17 16:56:27,738.738 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:56:27,739.739 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2022-12-17 16:56:27,740.740 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2022-12-17 16:56:27,741.741 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2022-12-17 16:56:27,742.742 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:56:27,743.743 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:56:27,744.744 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:56:27,745.745 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2022-12-17 16:56:27,746.746 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:56:27,747.747 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2022-12-17 16:56:27,748.748 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:56:27,749.749 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:56:27,750.750 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:56:27,751.751 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2022-12-17 16:56:27,752.752 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:56:27,753.753 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:56:27,754.754 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:56:27,755.755 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:56:27,755.755 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2022-12-17 16:56:27,755.755 2527:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2022-12-17 16:56:27,755.755 2527:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2022-12-17 16:56:27,755.755 2527:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2022-12-17 16:56:27,755.755 2527:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2022-12-17 16:56:27,755.755 2527:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2022-12-17 16:56:27,755.755 2527:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2022-12-17 16:56:27,755.755 2527:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2022-12-17 16:56:27,757.757 2527:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2022-12-17 16:56:27,848.848 2527:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
2022-12-17 16:56:48,697.697 2527:inference.py:111 test_git_inference_single_image(): output: a wall on the side of a building
2022-12-17 16:56:52,141.141 2549:inference.py:320   <module>(): param:
{'image_path': '../img8/img8_2.png',
 'model_name': 'GIT_BASE',
 'prefix': '',
 'type': 'test_git_inference_single_image'}
2022-12-17 16:57:00,525.525 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2022-12-17 16:57:00,526.526 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2022-12-17 16:57:00,526.526 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2022-12-17 16:57:00,526.526 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2022-12-17 16:57:00,526.526 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2022-12-17 16:57:00,527.527 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2022-12-17 16:57:00,527.527 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2022-12-17 16:57:00,527.527 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2022-12-17 16:57:00,527.527 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:00,527.527 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:00,528.528 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:00,528.528 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:00,528.528 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2022-12-17 16:57:00,528.528 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2022-12-17 16:57:00,528.528 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2022-12-17 16:57:00,529.529 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2022-12-17 16:57:00,529.529 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:00,529.529 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:00,529.529 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:00,529.529 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:00,529.529 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:00,530.530 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:00,530.530 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:00,530.530 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:00,530.530 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2022-12-17 16:57:00,530.530 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2022-12-17 16:57:00,530.530 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2022-12-17 16:57:00,531.531 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2022-12-17 16:57:00,531.531 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:00,531.531 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:00,531.531 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:00,531.531 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:00,532.532 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2022-12-17 16:57:00,532.532 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 16:57:00,532.532 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2022-12-17 16:57:00,532.532 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2022-12-17 16:57:00,532.532 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2022-12-17 16:57:00,532.532 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2022-12-17 16:57:00,533.533 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2022-12-17 16:57:00,533.533 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2022-12-17 16:57:00,533.533 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 16:57:00,533.533 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 16:57:00,533.533 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2022-12-17 16:57:00,534.534 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 16:57:00,534.534 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2022-12-17 16:57:00,534.534 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 16:57:00,534.534 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2022-12-17 16:57:00,534.534 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2022-12-17 16:57:00,534.534 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2022-12-17 16:57:00,535.535 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2022-12-17 16:57:00,535.535 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2022-12-17 16:57:00,535.535 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2022-12-17 16:57:00,535.535 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 16:57:00,535.535 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 16:57:00,536.536 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2022-12-17 16:57:00,536.536 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 16:57:00,536.536 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:00,536.536 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:00,536.536 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:00,537.537 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:00,537.537 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2022-12-17 16:57:00,537.537 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2022-12-17 16:57:00,537.537 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2022-12-17 16:57:00,537.537 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2022-12-17 16:57:00,538.538 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:00,538.538 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:00,538.538 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:00,538.538 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:00,538.538 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:00,538.538 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:00,539.539 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:00,539.539 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:00,539.539 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2022-12-17 16:57:00,539.539 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2022-12-17 16:57:00,539.539 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2022-12-17 16:57:00,540.540 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2022-12-17 16:57:00,540.540 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:00,540.540 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:00,540.540 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:00,540.540 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:00,540.540 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:00,541.541 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:00,541.541 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:00,541.541 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:00,541.541 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2022-12-17 16:57:00,541.541 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2022-12-17 16:57:00,541.541 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2022-12-17 16:57:00,541.541 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2022-12-17 16:57:00,542.542 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:00,542.542 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:00,542.542 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:00,542.542 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:00,542.542 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:00,543.543 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:00,543.543 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:00,543.543 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:00,543.543 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2022-12-17 16:57:00,543.543 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2022-12-17 16:57:00,544.544 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2022-12-17 16:57:00,544.544 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2022-12-17 16:57:00,544.544 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:00,544.544 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:00,544.544 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:00,544.544 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:00,545.545 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:00,545.545 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:00,545.545 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:00,545.545 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:00,545.545 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2022-12-17 16:57:00,546.546 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2022-12-17 16:57:00,546.546 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2022-12-17 16:57:00,546.546 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2022-12-17 16:57:00,546.546 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:00,546.546 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:00,546.546 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:00,547.547 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:00,547.547 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:00,547.547 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:00,547.547 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:00,547.547 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:00,547.547 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2022-12-17 16:57:00,548.548 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2022-12-17 16:57:00,548.548 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2022-12-17 16:57:00,548.548 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2022-12-17 16:57:00,548.548 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:00,548.548 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:00,548.548 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:00,549.549 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:00,549.549 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:00,549.549 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:00,549.549 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:00,549.549 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:00,550.550 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2022-12-17 16:57:00,550.550 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2022-12-17 16:57:00,550.550 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2022-12-17 16:57:00,550.550 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2022-12-17 16:57:00,550.550 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:00,550.550 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:00,551.551 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:00,551.551 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:00,551.551 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:00,551.551 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:00,552.552 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:00,552.552 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:00,552.552 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2022-12-17 16:57:00,552.552 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2022-12-17 16:57:00,552.552 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2022-12-17 16:57:00,553.553 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2022-12-17 16:57:00,553.553 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:00,553.553 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:00,553.553 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:00,554.554 2549:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:00,554.554 2549:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2022-12-17 16:57:00,554.554 2549:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2022-12-17 16:57:00,554.554 2549:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2022-12-17 16:57:00,554.554 2549:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2022-12-17 16:57:00,554.554 2549:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2022-12-17 16:57:00,555.555 2549:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2022-12-17 16:57:00,555.555 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:00,555.555 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:00,555.555 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:00,555.555 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:00,556.556 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:00,556.556 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:00,556.556 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:00,556.556 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:00,556.556 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:00,557.557 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:00,557.557 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:00,557.557 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:00,557.557 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:00,557.557 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:00,558.558 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2022-12-17 16:57:00,558.558 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:00,558.558 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:00,558.558 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:00,558.558 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:00,558.558 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:00,559.559 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:00,559.559 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:00,559.559 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:00,559.559 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:00,559.559 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:00,560.560 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:00,560.560 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:00,560.560 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:00,560.560 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:00,560.560 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:00,560.560 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2022-12-17 16:57:00,561.561 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:00,561.561 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:00,561.561 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:00,561.561 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:00,561.561 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:00,562.562 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:00,562.562 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:00,562.562 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:00,562.562 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:00,562.562 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:00,562.562 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:00,563.563 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:00,563.563 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:00,563.563 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:00,563.563 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:00,563.563 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2022-12-17 16:57:00,564.564 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:00,564.564 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:00,564.564 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:00,564.564 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:00,564.564 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:00,564.564 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:00,565.565 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:00,565.565 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:00,565.565 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:00,565.565 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:00,565.565 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:00,565.565 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:00,566.566 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:00,566.566 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:00,566.566 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:00,566.566 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2022-12-17 16:57:00,567.567 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:00,567.567 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:00,567.567 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:00,567.567 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:00,567.567 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:00,568.568 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:00,568.568 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:00,568.568 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:00,568.568 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:00,568.568 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:00,569.569 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:00,569.569 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:00,569.569 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:00,569.569 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:00,570.570 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:00,570.570 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2022-12-17 16:57:00,570.570 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:00,570.570 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:00,570.570 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:00,571.571 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:00,571.571 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:00,571.571 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:00,571.571 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:00,571.571 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:00,572.572 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:00,572.572 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:00,572.572 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:00,572.572 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:00,572.572 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:00,572.572 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:00,573.573 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:00,573.573 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2022-12-17 16:57:00,573.573 2549:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:00,573.573 2549:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2022-12-17 16:57:00,573.573 2549:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2022-12-17 16:57:00,574.574 2549:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2022-12-17 16:57:00,574.574 2549:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2022-12-17 16:57:00,574.574 2549:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2022-12-17 16:57:00,574.574 2549:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2022-12-17 16:57:00,578.578 2549:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2022-12-17 16:57:00,785.785 2549:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
2022-12-17 16:57:42,487.487 2549:inference.py:111 test_git_inference_single_image(): output: this is a crosswalk
2022-12-17 16:57:44,469.469 2586:inference.py:320   <module>(): param:
{'image_path': '../img8/img8_3.png',
 'model_name': 'GIT_BASE',
 'prefix': '',
 'type': 'test_git_inference_single_image'}
2022-12-17 16:57:54,248.248 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2022-12-17 16:57:54,249.249 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2022-12-17 16:57:54,249.249 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2022-12-17 16:57:54,249.249 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2022-12-17 16:57:54,249.249 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2022-12-17 16:57:54,250.250 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2022-12-17 16:57:54,250.250 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2022-12-17 16:57:54,250.250 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2022-12-17 16:57:54,250.250 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:54,250.250 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:54,251.251 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:54,251.251 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:54,251.251 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2022-12-17 16:57:54,251.251 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2022-12-17 16:57:54,251.251 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2022-12-17 16:57:54,251.251 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2022-12-17 16:57:54,251.251 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:54,252.252 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:54,252.252 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:54,252.252 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:54,252.252 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:54,252.252 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:54,252.252 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:54,252.252 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:54,253.253 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2022-12-17 16:57:54,253.253 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2022-12-17 16:57:54,253.253 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2022-12-17 16:57:54,253.253 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2022-12-17 16:57:54,253.253 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:54,253.253 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:54,253.253 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:54,254.254 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:54,254.254 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2022-12-17 16:57:54,254.254 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 16:57:54,254.254 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2022-12-17 16:57:54,254.254 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2022-12-17 16:57:54,254.254 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2022-12-17 16:57:54,254.254 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2022-12-17 16:57:54,254.254 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2022-12-17 16:57:54,254.254 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2022-12-17 16:57:54,255.255 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 16:57:54,255.255 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 16:57:54,255.255 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2022-12-17 16:57:54,255.255 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 16:57:54,255.255 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2022-12-17 16:57:54,255.255 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 16:57:54,255.255 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2022-12-17 16:57:54,255.255 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2022-12-17 16:57:54,255.255 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2022-12-17 16:57:54,256.256 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2022-12-17 16:57:54,256.256 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2022-12-17 16:57:54,256.256 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2022-12-17 16:57:54,256.256 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 16:57:54,256.256 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 16:57:54,256.256 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2022-12-17 16:57:54,256.256 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 16:57:54,257.257 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:54,257.257 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:54,257.257 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:54,257.257 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:54,257.257 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2022-12-17 16:57:54,257.257 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2022-12-17 16:57:54,257.257 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2022-12-17 16:57:54,257.257 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2022-12-17 16:57:54,258.258 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:54,258.258 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:54,258.258 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:54,258.258 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:54,258.258 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:54,258.258 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:54,259.259 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:54,259.259 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:54,259.259 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2022-12-17 16:57:54,259.259 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2022-12-17 16:57:54,259.259 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2022-12-17 16:57:54,259.259 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2022-12-17 16:57:54,260.260 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:54,260.260 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:54,260.260 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:54,260.260 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:54,260.260 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:54,260.260 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:54,261.261 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:54,261.261 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:54,261.261 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2022-12-17 16:57:54,261.261 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2022-12-17 16:57:54,261.261 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2022-12-17 16:57:54,262.262 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2022-12-17 16:57:54,262.262 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:54,262.262 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:54,262.262 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:54,262.262 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:54,262.262 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:54,263.263 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:54,263.263 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:54,263.263 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:54,263.263 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2022-12-17 16:57:54,263.263 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2022-12-17 16:57:54,263.263 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2022-12-17 16:57:54,263.263 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2022-12-17 16:57:54,263.263 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:54,264.264 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:54,264.264 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:54,264.264 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:54,264.264 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:54,264.264 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:54,264.264 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:54,265.265 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:54,265.265 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2022-12-17 16:57:54,265.265 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2022-12-17 16:57:54,265.265 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2022-12-17 16:57:54,265.265 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2022-12-17 16:57:54,265.265 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:54,265.265 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:54,265.265 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:54,266.266 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:54,266.266 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:54,266.266 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:54,266.266 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:54,266.266 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:54,266.266 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2022-12-17 16:57:54,266.266 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2022-12-17 16:57:54,267.267 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2022-12-17 16:57:54,267.267 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2022-12-17 16:57:54,267.267 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:54,267.267 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:54,267.267 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:54,268.268 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:54,268.268 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:54,268.268 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:54,268.268 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:54,268.268 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:54,268.268 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2022-12-17 16:57:54,268.268 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2022-12-17 16:57:54,269.269 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2022-12-17 16:57:54,269.269 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2022-12-17 16:57:54,269.269 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:54,269.269 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:54,269.269 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:54,269.269 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:54,269.269 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:57:54,270.270 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:57:54,270.270 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2022-12-17 16:57:54,270.270 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:57:54,270.270 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2022-12-17 16:57:54,270.270 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2022-12-17 16:57:54,270.270 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2022-12-17 16:57:54,270.270 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2022-12-17 16:57:54,271.271 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:57:54,271.271 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:57:54,271.271 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:57:54,271.271 2586:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:57:54,271.271 2586:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2022-12-17 16:57:54,271.271 2586:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2022-12-17 16:57:54,272.272 2586:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2022-12-17 16:57:54,272.272 2586:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2022-12-17 16:57:54,272.272 2586:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2022-12-17 16:57:54,272.272 2586:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2022-12-17 16:57:54,272.272 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:54,272.272 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:54,272.272 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:54,273.273 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:54,273.273 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:54,273.273 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:54,273.273 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:54,273.273 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:54,273.273 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:54,273.273 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:54,274.274 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:54,274.274 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:54,274.274 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:54,274.274 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:54,274.274 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2022-12-17 16:57:54,274.274 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:54,274.274 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:54,275.275 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:54,275.275 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:54,275.275 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:54,275.275 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:54,276.276 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:54,276.276 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:54,276.276 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:54,276.276 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:54,276.276 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:54,277.277 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:54,277.277 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:54,277.277 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:54,277.277 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:54,277.277 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2022-12-17 16:57:54,277.277 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:54,278.278 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:54,278.278 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:54,278.278 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:54,278.278 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:54,278.278 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:54,278.278 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:54,279.279 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:54,279.279 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:54,279.279 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:54,279.279 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:54,279.279 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:54,280.280 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:54,280.280 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:54,280.280 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:54,280.280 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2022-12-17 16:57:54,280.280 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:54,281.281 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:54,281.281 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:54,281.281 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:54,281.281 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:54,281.281 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:54,281.281 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:54,282.282 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:54,282.282 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:54,282.282 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:54,282.282 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:54,283.283 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:54,283.283 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:54,283.283 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:54,283.283 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:54,284.284 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2022-12-17 16:57:54,284.284 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:54,284.284 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:54,284.284 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:54,284.284 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:54,284.284 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:54,285.285 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:54,285.285 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:54,285.285 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:54,285.285 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:54,285.285 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:54,286.286 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:54,286.286 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:54,286.286 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:54,286.286 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:54,286.286 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:54,286.286 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2022-12-17 16:57:54,286.286 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:54,287.287 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:57:54,287.287 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:57:54,287.287 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2022-12-17 16:57:54,287.287 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:57:54,287.287 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2022-12-17 16:57:54,287.287 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:57:54,287.287 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2022-12-17 16:57:54,287.287 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:57:54,287.287 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2022-12-17 16:57:54,287.287 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:57:54,288.288 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:57:54,288.288 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:57:54,288.288 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:57:54,288.288 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:57:54,288.288 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2022-12-17 16:57:54,288.288 2586:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2022-12-17 16:57:54,288.288 2586:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2022-12-17 16:57:54,289.289 2586:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2022-12-17 16:57:54,289.289 2586:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2022-12-17 16:57:54,289.289 2586:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2022-12-17 16:57:54,289.289 2586:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2022-12-17 16:57:54,290.290 2586:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2022-12-17 16:57:54,294.294 2586:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2022-12-17 16:57:54,486.486 2586:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
2022-12-17 16:58:27,208.208 2586:inference.py:111 test_git_inference_single_image(): output: a wall on the side of a building
2022-12-17 16:58:35,839.839 2643:inference.py:320   <module>(): param:
{'image_path': '../img8/img8_4.png',
 'model_name': 'GIT_BASE',
 'prefix': '',
 'type': 'test_git_inference_single_image'}
2022-12-17 16:58:56,064.064 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.class_embedding                                         will be loaded from image_encoder.class_embedding                                         of shape (768,)
2022-12-17 16:58:56,066.066 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.conv1.weight                                            will be loaded from image_encoder.conv1.weight                                            of shape (768, 3, 16, 16)
2022-12-17 16:58:56,067.067 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.bias                                            will be loaded from image_encoder.ln_post.bias                                            of shape (768,)
2022-12-17 16:58:56,067.067 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_post.weight                                          will be loaded from image_encoder.ln_post.weight                                          of shape (768,)
2022-12-17 16:58:56,067.067 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.bias                                             will be loaded from image_encoder.ln_pre.bias                                             of shape (768,)
2022-12-17 16:58:56,068.068 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.ln_pre.weight                                           will be loaded from image_encoder.ln_pre.weight                                           of shape (768,)
2022-12-17 16:58:56,068.068 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.positional_embedding                                    will be loaded from image_encoder.positional_embedding                                    of shape (197, 768)
2022-12-17 16:58:56,068.068 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.proj                                                    will be loaded from image_encoder.proj                                                    of shape (768, 512)
2022-12-17 16:58:56,068.068 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:58:56,069.069 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.0.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:58:56,069.069 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.bias              of shape (768,)
2022-12-17 16:58:56,069.069 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.0.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:58:56,070.070 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_1.bias                       of shape (768,)
2022-12-17 16:58:56,070.070 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_1.weight                     of shape (768,)
2022-12-17 16:58:56,070.070 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.0.ln_2.bias                       of shape (768,)
2022-12-17 16:58:56,070.070 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.0.ln_2.weight                     of shape (768,)
2022-12-17 16:58:56,071.071 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:58:56,071.071 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:58:56,071.071 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:58:56,071.071 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.0.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.0.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:58:56,072.072 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:58:56,072.072 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.1.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:58:56,072.072 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.bias              of shape (768,)
2022-12-17 16:58:56,073.073 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.1.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:58:56,073.073 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_1.bias                       of shape (768,)
2022-12-17 16:58:56,073.073 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_1.weight                     of shape (768,)
2022-12-17 16:58:56,074.074 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.1.ln_2.bias                       of shape (768,)
2022-12-17 16:58:56,074.074 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.1.ln_2.weight                     of shape (768,)
2022-12-17 16:58:56,075.075 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:58:56,075.075 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:58:56,075.075 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:58:56,076.076 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.1.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.1.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:58:56,076.076 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_bias              of shape (2304,)
2022-12-17 16:58:56,077.077 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.10.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 16:58:56,077.077 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.bias             of shape (768,)
2022-12-17 16:58:56,077.077 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.10.attn.out_proj.weight           of shape (768, 768)
2022-12-17 16:58:56,078.078 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_1.bias                      of shape (768,)
2022-12-17 16:58:56,078.078 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_1.weight                    of shape (768,)
2022-12-17 16:58:56,078.078 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.10.ln_2.bias                      of shape (768,)
2022-12-17 16:58:56,078.078 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.10.ln_2.weight                    of shape (768,)
2022-12-17 16:58:56,079.079 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 16:58:56,079.079 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 16:58:56,080.080 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.bias                of shape (768,)
2022-12-17 16:58:56,080.080 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.10.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.10.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 16:58:56,080.080 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_bias              will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_bias              of shape (2304,)
2022-12-17 16:58:56,081.081 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.in_proj_weight            will be loaded from image_encoder.transformer.resblocks.11.attn.in_proj_weight            of shape (2304, 768)
2022-12-17 16:58:56,081.081 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.bias             will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.bias             of shape (768,)
2022-12-17 16:58:56,081.081 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.attn.out_proj.weight           will be loaded from image_encoder.transformer.resblocks.11.attn.out_proj.weight           of shape (768, 768)
2022-12-17 16:58:56,082.082 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_1.bias                      of shape (768,)
2022-12-17 16:58:56,082.082 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_1.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_1.weight                    of shape (768,)
2022-12-17 16:58:56,083.083 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.bias                      will be loaded from image_encoder.transformer.resblocks.11.ln_2.bias                      of shape (768,)
2022-12-17 16:58:56,083.083 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.ln_2.weight                    will be loaded from image_encoder.transformer.resblocks.11.ln_2.weight                    of shape (768,)
2022-12-17 16:58:56,083.083 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.bias                  of shape (3072,)
2022-12-17 16:58:56,083.083 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_fc.weight                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_fc.weight                of shape (3072, 768)
2022-12-17 16:58:56,084.084 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.bias                will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.bias                of shape (768,)
2022-12-17 16:58:56,084.084 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.11.mlp.c_proj.weight              will be loaded from image_encoder.transformer.resblocks.11.mlp.c_proj.weight              of shape (768, 3072)
2022-12-17 16:58:56,085.085 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:58:56,085.085 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.2.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:58:56,085.085 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.bias              of shape (768,)
2022-12-17 16:58:56,085.085 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.2.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:58:56,086.086 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_1.bias                       of shape (768,)
2022-12-17 16:58:56,086.086 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_1.weight                     of shape (768,)
2022-12-17 16:58:56,086.086 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.2.ln_2.bias                       of shape (768,)
2022-12-17 16:58:56,087.087 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.2.ln_2.weight                     of shape (768,)
2022-12-17 16:58:56,087.087 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:58:56,087.087 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:58:56,088.088 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:58:56,088.088 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.2.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.2.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:58:56,089.089 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:58:56,089.089 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.3.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:58:56,089.089 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.bias              of shape (768,)
2022-12-17 16:58:56,089.089 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.3.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:58:56,090.090 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_1.bias                       of shape (768,)
2022-12-17 16:58:56,090.090 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_1.weight                     of shape (768,)
2022-12-17 16:58:56,090.090 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.3.ln_2.bias                       of shape (768,)
2022-12-17 16:58:56,091.091 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.3.ln_2.weight                     of shape (768,)
2022-12-17 16:58:56,091.091 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:58:56,091.091 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:58:56,091.091 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:58:56,092.092 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.3.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.3.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:58:56,092.092 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:58:56,092.092 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.4.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:58:56,093.093 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.bias              of shape (768,)
2022-12-17 16:58:56,093.093 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.4.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:58:56,093.093 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_1.bias                       of shape (768,)
2022-12-17 16:58:56,094.094 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_1.weight                     of shape (768,)
2022-12-17 16:58:56,094.094 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.4.ln_2.bias                       of shape (768,)
2022-12-17 16:58:56,094.094 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.4.ln_2.weight                     of shape (768,)
2022-12-17 16:58:56,094.094 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:58:56,095.095 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:58:56,095.095 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:58:56,095.095 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.4.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.4.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:58:56,096.096 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:58:56,096.096 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.5.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:58:56,096.096 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.bias              of shape (768,)
2022-12-17 16:58:56,097.097 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.5.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:58:56,097.097 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_1.bias                       of shape (768,)
2022-12-17 16:58:56,097.097 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_1.weight                     of shape (768,)
2022-12-17 16:58:56,097.097 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.5.ln_2.bias                       of shape (768,)
2022-12-17 16:58:56,098.098 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.5.ln_2.weight                     of shape (768,)
2022-12-17 16:58:56,098.098 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:58:56,098.098 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:58:56,098.098 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:58:56,098.098 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.5.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.5.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:58:56,099.099 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:58:56,099.099 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.6.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:58:56,099.099 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.bias              of shape (768,)
2022-12-17 16:58:56,100.100 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.6.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:58:56,100.100 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_1.bias                       of shape (768,)
2022-12-17 16:58:56,100.100 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_1.weight                     of shape (768,)
2022-12-17 16:58:56,100.100 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.6.ln_2.bias                       of shape (768,)
2022-12-17 16:58:56,101.101 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.6.ln_2.weight                     of shape (768,)
2022-12-17 16:58:56,101.101 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:58:56,101.101 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:58:56,101.101 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:58:56,102.102 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.6.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.6.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:58:56,102.102 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:58:56,102.102 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.7.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:58:56,103.103 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.bias              of shape (768,)
2022-12-17 16:58:56,103.103 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.7.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:58:56,104.104 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_1.bias                       of shape (768,)
2022-12-17 16:58:56,104.104 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_1.weight                     of shape (768,)
2022-12-17 16:58:56,104.104 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.7.ln_2.bias                       of shape (768,)
2022-12-17 16:58:56,105.105 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.7.ln_2.weight                     of shape (768,)
2022-12-17 16:58:56,105.105 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:58:56,105.105 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:58:56,106.106 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:58:56,106.106 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.7.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.7.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:58:56,106.106 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:58:56,107.107 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.8.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:58:56,107.107 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.bias              of shape (768,)
2022-12-17 16:58:56,107.107 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.8.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:58:56,107.107 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_1.bias                       of shape (768,)
2022-12-17 16:58:56,108.108 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_1.weight                     of shape (768,)
2022-12-17 16:58:56,108.108 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.8.ln_2.bias                       of shape (768,)
2022-12-17 16:58:56,108.108 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.8.ln_2.weight                     of shape (768,)
2022-12-17 16:58:56,108.108 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:58:56,109.109 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:58:56,109.109 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:58:56,109.109 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.8.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.8.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:58:56,109.109 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_bias               will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_bias               of shape (2304,)
2022-12-17 16:58:56,110.110 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.in_proj_weight             will be loaded from image_encoder.transformer.resblocks.9.attn.in_proj_weight             of shape (2304, 768)
2022-12-17 16:58:56,110.110 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.bias              will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.bias              of shape (768,)
2022-12-17 16:58:56,110.110 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.attn.out_proj.weight            will be loaded from image_encoder.transformer.resblocks.9.attn.out_proj.weight            of shape (768, 768)
2022-12-17 16:58:56,111.111 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_1.bias                       of shape (768,)
2022-12-17 16:58:56,111.111 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_1.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_1.weight                     of shape (768,)
2022-12-17 16:58:56,111.111 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.bias                       will be loaded from image_encoder.transformer.resblocks.9.ln_2.bias                       of shape (768,)
2022-12-17 16:58:56,111.111 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.ln_2.weight                     will be loaded from image_encoder.transformer.resblocks.9.ln_2.weight                     of shape (768,)
2022-12-17 16:58:56,112.112 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.bias                   of shape (3072,)
2022-12-17 16:58:56,112.112 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_fc.weight                 of shape (3072, 768)
2022-12-17 16:58:56,112.112 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.bias                 of shape (768,)
2022-12-17 16:58:56,112.112 2643:torch_common.py:128 align_and_update_state_dicts(): image_encoder.transformer.resblocks.9.mlp.c_proj.weight               will be loaded from image_encoder.transformer.resblocks.9.mlp.c_proj.weight               of shape (768, 3072)
2022-12-17 16:58:56,113.113 2643:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.bias                                     will be loaded from textual.embedding.layer_norm.bias                                     of shape (768,)
2022-12-17 16:58:56,113.113 2643:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.layer_norm.weight                                   will be loaded from textual.embedding.layer_norm.weight                                   of shape (768,)
2022-12-17 16:58:56,113.113 2643:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.positions.weight                                    will be loaded from textual.embedding.positions.weight                                    of shape (1024, 768)
2022-12-17 16:58:56,114.114 2643:torch_common.py:128 align_and_update_state_dicts(): textual.embedding.words.weight                                        will be loaded from textual.embedding.words.weight                                        of shape (30522, 768)
2022-12-17 16:58:56,114.114 2643:torch_common.py:128 align_and_update_state_dicts(): textual.output.bias                                                   will be loaded from textual.output.bias                                                   of shape (30522,)
2022-12-17 16:58:56,114.114 2643:torch_common.py:128 align_and_update_state_dicts(): textual.output.weight                                                 will be loaded from textual.output.weight                                                 of shape (30522, 768)
2022-12-17 16:58:56,114.114 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:58:56,115.115 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.0.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:58:56,115.115 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.bias       of shape (768,)
2022-12-17 16:58:56,115.115 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.0.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:58:56,115.115 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.0.attention.self.key.bias           of shape (768,)
2022-12-17 16:58:56,116.116 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.0.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:58:56,116.116 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.query.bias         of shape (768,)
2022-12-17 16:58:56,116.116 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:58:56,117.117 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.0.attention.self.value.bias         of shape (768,)
2022-12-17 16:58:56,117.117 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.0.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:58:56,117.117 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:58:56,118.118 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.0.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:58:56,118.118 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:58:56,118.118 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.0.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:58:56,118.118 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.0.output.dense.bias                 of shape (768,)
2022-12-17 16:58:56,119.119 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.0.output.dense.weight               will be loaded from textual.transformer.encoder.layer.0.output.dense.weight               of shape (768, 3072)
2022-12-17 16:58:56,119.119 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:58:56,119.119 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.1.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:58:56,120.120 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.bias       of shape (768,)
2022-12-17 16:58:56,120.120 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.1.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:58:56,120.120 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.1.attention.self.key.bias           of shape (768,)
2022-12-17 16:58:56,120.120 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.1.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:58:56,121.121 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.query.bias         of shape (768,)
2022-12-17 16:58:56,121.121 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:58:56,121.121 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.1.attention.self.value.bias         of shape (768,)
2022-12-17 16:58:56,121.121 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.1.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:58:56,122.122 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:58:56,122.122 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.1.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:58:56,123.123 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:58:56,123.123 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.1.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:58:56,123.123 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.1.output.dense.bias                 of shape (768,)
2022-12-17 16:58:56,123.123 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.1.output.dense.weight               will be loaded from textual.transformer.encoder.layer.1.output.dense.weight               of shape (768, 3072)
2022-12-17 16:58:56,124.124 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:58:56,124.124 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.2.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:58:56,124.124 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.bias       of shape (768,)
2022-12-17 16:58:56,125.125 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.2.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:58:56,125.125 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.2.attention.self.key.bias           of shape (768,)
2022-12-17 16:58:56,125.125 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.2.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:58:56,125.125 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.query.bias         of shape (768,)
2022-12-17 16:58:56,126.126 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:58:56,126.126 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.2.attention.self.value.bias         of shape (768,)
2022-12-17 16:58:56,126.126 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.2.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:58:56,127.127 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:58:56,127.127 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.2.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:58:56,127.127 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:58:56,127.127 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.2.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:58:56,128.128 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.2.output.dense.bias                 of shape (768,)
2022-12-17 16:58:56,128.128 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.2.output.dense.weight               will be loaded from textual.transformer.encoder.layer.2.output.dense.weight               of shape (768, 3072)
2022-12-17 16:58:56,128.128 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:58:56,129.129 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.3.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:58:56,129.129 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.bias       of shape (768,)
2022-12-17 16:58:56,129.129 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.3.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:58:56,130.130 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.3.attention.self.key.bias           of shape (768,)
2022-12-17 16:58:56,130.130 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.3.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:58:56,130.130 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.query.bias         of shape (768,)
2022-12-17 16:58:56,130.130 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:58:56,131.131 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.3.attention.self.value.bias         of shape (768,)
2022-12-17 16:58:56,131.131 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.3.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:58:56,131.131 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:58:56,132.132 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.3.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:58:56,132.132 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:58:56,132.132 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.3.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:58:56,132.132 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.3.output.dense.bias                 of shape (768,)
2022-12-17 16:58:56,132.132 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.3.output.dense.weight               will be loaded from textual.transformer.encoder.layer.3.output.dense.weight               of shape (768, 3072)
2022-12-17 16:58:56,133.133 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:58:56,133.133 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.4.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:58:56,133.133 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.bias       of shape (768,)
2022-12-17 16:58:56,133.133 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.4.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:58:56,134.134 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.4.attention.self.key.bias           of shape (768,)
2022-12-17 16:58:56,134.134 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.4.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:58:56,134.134 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.query.bias         of shape (768,)
2022-12-17 16:58:56,134.134 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:58:56,135.135 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.4.attention.self.value.bias         of shape (768,)
2022-12-17 16:58:56,135.135 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.4.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:58:56,136.136 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:58:56,136.136 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.4.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:58:56,136.136 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:58:56,137.137 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.4.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:58:56,137.137 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.4.output.dense.bias                 of shape (768,)
2022-12-17 16:58:56,137.137 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.4.output.dense.weight               will be loaded from textual.transformer.encoder.layer.4.output.dense.weight               of shape (768, 3072)
2022-12-17 16:58:56,138.138 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.bias   of shape (768,)
2022-12-17 16:58:56,138.138 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight will be loaded from textual.transformer.encoder.layer.5.attention.output.LayerNorm.weight of shape (768,)
2022-12-17 16:58:56,138.138 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.bias       will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.bias       of shape (768,)
2022-12-17 16:58:56,139.139 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.output.dense.weight     will be loaded from textual.transformer.encoder.layer.5.attention.output.dense.weight     of shape (768, 768)
2022-12-17 16:58:56,139.139 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.bias           will be loaded from textual.transformer.encoder.layer.5.attention.self.key.bias           of shape (768,)
2022-12-17 16:58:56,139.139 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.key.weight         will be loaded from textual.transformer.encoder.layer.5.attention.self.key.weight         of shape (768, 768)
2022-12-17 16:58:56,140.140 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.query.bias         of shape (768,)
2022-12-17 16:58:56,140.140 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.query.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.query.weight       of shape (768, 768)
2022-12-17 16:58:56,140.140 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.bias         will be loaded from textual.transformer.encoder.layer.5.attention.self.value.bias         of shape (768,)
2022-12-17 16:58:56,141.141 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.attention.self.value.weight       will be loaded from textual.transformer.encoder.layer.5.attention.self.value.weight       of shape (768, 768)
2022-12-17 16:58:56,141.141 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.bias           will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.bias           of shape (3072,)
2022-12-17 16:58:56,141.141 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.intermediate.dense.weight         will be loaded from textual.transformer.encoder.layer.5.intermediate.dense.weight         of shape (3072, 768)
2022-12-17 16:58:56,142.142 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.bias             will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.bias             of shape (768,)
2022-12-17 16:58:56,142.142 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.LayerNorm.weight           will be loaded from textual.transformer.encoder.layer.5.output.LayerNorm.weight           of shape (768,)
2022-12-17 16:58:56,142.142 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.bias                 will be loaded from textual.transformer.encoder.layer.5.output.dense.bias                 of shape (768,)
2022-12-17 16:58:56,142.142 2643:torch_common.py:128 align_and_update_state_dicts(): textual.transformer.encoder.layer.5.output.dense.weight               will be loaded from textual.transformer.encoder.layer.5.output.dense.weight               of shape (768, 3072)
2022-12-17 16:58:56,142.142 2643:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.bias                                      will be loaded from textual.visual_projection.0.bias                                      of shape (768,)
2022-12-17 16:58:56,143.143 2643:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.0.weight                                    will be loaded from textual.visual_projection.0.weight                                    of shape (768, 768)
2022-12-17 16:58:56,143.143 2643:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.bias                                      will be loaded from textual.visual_projection.1.bias                                      of shape (768,)
2022-12-17 16:58:56,143.143 2643:torch_common.py:128 align_and_update_state_dicts(): textual.visual_projection.1.weight                                    will be loaded from textual.visual_projection.1.weight                                    of shape (768,)
2022-12-17 16:58:56,143.143 2643:torch_common.py:137 align_and_update_state_dicts(): target model param = 258; name matched = 258; loaded = 258
2022-12-17 16:58:56,144.144 2643:torch_common.py:140 align_and_update_state_dicts(): from loaded; ignore = []
2022-12-17 16:58:56,149.149 2643:torch_common.py:82 load_model_state_ignore_mismatch(): unique keys in init dict = ['textual.output.weight']; total = 1
2022-12-17 16:58:56,764.764 2643:torch_common.py:86 load_model_state_ignore_mismatch(): unique key (not initialized) in current model = ['textual.output.weight']
2022-12-17 16:59:39,547.547 2643:inference.py:111 test_git_inference_single_image(): output: a wall on the side of a building
